# NLP Preâ€‘Processing Work

Bu Ã§alÄ±ÅŸma, 2023 yazÄ±nda gerÃ§ekleÅŸtirdiÄŸim bir staj sÃ¼recinde yaptÄ±ÄŸÄ±m **baÅŸlangÄ±Ã§ seviyesi bir doÄŸal dil iÅŸleme (NLP) Ã¶n iÅŸleme projesidir**. AmaÃ§, metin verileri Ã¼zerinde temel Ã¶n iÅŸleme adÄ±mlarÄ±nÄ± uygulayarak bu verileri analiz ve modelleme iÃ§in hazÄ±r hÃ¢le getirmektir.

---

## Ä°Ã§indekiler

- [Genel BakÄ±ÅŸ](#genel-bakÄ±ÅŸ)  
- [KullanÄ±lan Teknolojiler](#kullanÄ±lan-teknolojiler)  
- [Ã–n Ä°ÅŸleme AdÄ±mlarÄ±](#Ã¶n-iÌ‡ÅŸleme-adÄ±mlarÄ±)  
  - Temizleme  
  - Tokenizasyon  
  - Stop-word Ã§Ä±karÄ±mÄ±  
  - Stemming ve Lemmatization  
- [NasÄ±l KullanÄ±lÄ±r?](#nasÄ±l-kullanÄ±lÄ±r)

---

## Genel BakÄ±ÅŸ

Bu proje, metin verilerini analiz ve modelleme adÄ±mlarÄ±na hazÄ±rlamak iÃ§in gereken yaygÄ±n NLP Ã¶n iÅŸlem tekniklerini iÃ§erir. Hedeflenen temel iÅŸlemler:

- Ham metinleri temizlemek (HTML, URL, rakam, Ã¶zel karakter vb.)
- Metni tokenize edip anlamlÄ± parÃ§alara bÃ¶lmek
- Gereksiz kelimeleri Ã§Ä±karmak (stopâ€‘words)
- Kelimelerin temeldeki hÃ¢line dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi (stemming/lemmatization)

Bu adÄ±mlar sayesinde sentiment analizi, metin sÄ±nÄ±flandÄ±rma veya konu modelleme gibi NLP gÃ¶revleri iÃ§in veri hazÄ±rlÄ±ÄŸÄ± saÄŸlanÄ±r.

---

## KullanÄ±lan Teknolojiler

| Teknoloji            | KullanÄ±m AlanÄ±                      |
|----------------------|-------------------------------------|
| Python               | Temel programlama dili              |
| regex                | Metin temizleme (Ã¶rneÄŸin URLâ€™ler)   |
| NLTK / SpaCy         | Tokenizasyon, stopâ€‘word, lemmatizer |
| BeautifulSoup        | HTML etiket temizleme               |
| Gensim, Scikitâ€‘Learn | VektÃ¶r dÃ¶nÃ¼ÅŸÃ¼mleri (Ã¶rneÄŸin TFâ€‘IDF) |

---

## Ã–n Ä°ÅŸleme AdÄ±mlarÄ±

### ğŸ§¼ 1. Temizleme (Cleaning)

- KÃ¼Ã§Ã¼k harfe dÃ¶nÃ¼ÅŸtÃ¼rme (lowercase)
- HTML/XML etiketlerinin kaldÄ±rÄ±lmasÄ±
- URL, eâ€‘posta ve sayÄ±lar gibi Ã¶zel desenlerin silinmesi
- Noktalama iÅŸaretleri ve gereksiz karakterlerin temizlenmesi

### âœ‚ï¸ 2. Tokenizasyon

- CÃ¼mle ve kelime bazÄ±nda bÃ¶lme (Ã¶rneÄŸin `nltk.tokenize.word_tokenize`)
- GerektiÄŸinde Ã¶zel tokenizasyon (Ã¶rneÄŸin tweet, chat dili)

### ğŸš« 3. Stopâ€‘Word Ã‡Ä±karÄ±mÄ±

- SÄ±k kullanÄ±lan anlamsÄ±z kelimelerin (Ã¶rneÄŸin â€œveâ€, â€œtheâ€, â€œisâ€) metinden Ã§Ä±karÄ±lmasÄ±

### ğŸŒ± 4. KÃ¶k ve Lemma Ä°ÅŸlemleri

- **Stemming**: Kelimeleri kÃ¶k hÃ¢line (stem) indirgeme
- **Lemmatization**: BaÄŸlama gÃ¶re anlamlÄ± hÃ¢le lemmatize etme

---

## NasÄ±l KullanÄ±lÄ±r?

1. Bu depoyu klonlayÄ±n:

   ```bash
   git clone https://github.com/sefiye-arican/NLP-pre-processing-work.git
   cd NLP-pre-processing-work

2. Gerekli kÃ¼tÃ¼phaneleri kurun:
   ```bash
    pip install -r requirements.txt
   
3. Python ortamÄ±nda Ã¶rnek notebook'larÄ± aÃ§arak takip edin:
    ```bash
    jupyter notebook

- `text_cleaning.ipynb` (veya diÄŸer notebook dosyalarÄ±) Ã¼zerinde anlatÄ±mlÄ± Ã¶rnekler yer almaktadÄ±r.

4. AdÄ±m adÄ±m uygulama:

  - `clean_text()` fonksiyonu ile temizlik  
  - `tokenize_text()` ile tokenizasyon  
  - `remove_stopwords()` ile stopâ€‘word Ã§Ä±karÄ±mÄ±  
  - `stem_or_lemmatize()` ile kelime kÃ¶kÃ¼ne ya da lemmaâ€™ya dÃ¶nÃ¼ÅŸtÃ¼rme
